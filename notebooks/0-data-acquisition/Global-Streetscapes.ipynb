{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global StreetScapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_from_huggingface\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b318d1c174c480cb7b85e91c51b15c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading files:   0%|          | 0/21 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'climate.csv' already exists in the directory. Skipping download.\n",
      "File 'contextual.csv' already exists in the directory. Skipping download.\n",
      "File 'ephem.csv' already exists in the directory. Skipping download.\n",
      "File 'gadm.csv' already exists in the directory. Skipping download.\n",
      "File 'ghsl.csv' already exists in the directory. Skipping download.\n",
      "File 'h3.csv' already exists in the directory. Skipping download.\n",
      "File 'instances.csv' already exists in the directory. Skipping download.\n",
      "File 'metadata_common_attributes.csv' already exists in the directory. Skipping download.\n",
      "File 'metadata_kv.csv' already exists in the directory. Skipping download.\n",
      "File 'metadata_mly1.csv' already exists in the directory. Skipping download.\n",
      "File 'metadata_mly2.csv' already exists in the directory. Skipping download.\n",
      "File 'metadata_mly3.csv' already exists in the directory. Skipping download.\n",
      "File 'metadata_mly4.csv' already exists in the directory. Skipping download.\n",
      "File 'metadata_mly5.csv' already exists in the directory. Skipping download.\n",
      "File 'osm.csv' already exists in the directory. Skipping download.\n",
      "File 'perception.csv' already exists in the directory. Skipping download.\n",
      "File 'places365.csv' already exists in the directory. Skipping download.\n",
      "File 'season.csv' already exists in the directory. Skipping download.\n",
      "File 'segmentation.csv' already exists in the directory. Skipping download.\n",
      "File 'simplemaps.csv' already exists in the directory. Skipping download.\n",
      "File 'speed.csv' already exists in the directory. Skipping download.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93322a8e2614ade9242a37caf036e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading files:   0%|          | 0/2 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'cities688.csv' already exists in the directory. Skipping download.\n",
      "File 'info.csv' already exists in the directory. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Download Global StreetScapes data from Hugging Face\n",
    "# The entire folder is approximately 37GB. You can choose to download specific files instead.\n",
    "repo_id = \"NUS-UAL/global-streetscapes\"\n",
    "repo_type = \"dataset\"\n",
    "folder_path = \"data/\"\n",
    "local_dir_folder = \"../../data/0-raw/Global-StreetScapes/\"\n",
    "local_dir_files = \"../../data/0-raw/Global-StreetScapes/info\"\n",
    "file_list = [\"cities688.csv\", \"info.csv\"]\n",
    "\n",
    "# Download the entire 'data' folder directly into the specified local directory\n",
    "download_from_huggingface(repo_id, repo_type, folder_path=folder_path, local_dir=local_dir_folder)\n",
    "\n",
    "# Download specific files into the 'info' directory\n",
    "download_from_huggingface(repo_id, repo_type, file_paths=file_list, local_dir=local_dir_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>img_count</th>\n",
       "      <th>continent</th>\n",
       "      <th>koppen_geiger_zone</th>\n",
       "      <th>zone_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>281033</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Cfb</td>\n",
       "      <td>Marine west coast, warm summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Athens</td>\n",
       "      <td>106003</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Csa</td>\n",
       "      <td>Mediterranean, hot summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Lisbon</td>\n",
       "      <td>87461</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Csa</td>\n",
       "      <td>Mediterranean, hot summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>London</td>\n",
       "      <td>41837</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Cfb</td>\n",
       "      <td>Marine west coast, warm summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>26421</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Cfb</td>\n",
       "      <td>Marine west coast, warm summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>21218</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Csa</td>\n",
       "      <td>Mediterranean, hot summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  img_count continent koppen_geiger_zone  \\\n",
       "456     Berlin     281033    Europe                Cfb   \n",
       "396     Athens     106003    Europe                Csa   \n",
       "321     Lisbon      87461    Europe                Csa   \n",
       "368     London      41837    Europe                Cfb   \n",
       "221  Amsterdam      26421    Europe                Cfb   \n",
       "508  Barcelona      21218    Europe                Csa   \n",
       "\n",
       "                   zone_description  \n",
       "456  Marine west coast, warm summer  \n",
       "396       Mediterranean, hot summer  \n",
       "321       Mediterranean, hot summer  \n",
       "368  Marine west coast, warm summer  \n",
       "221  Marine west coast, warm summer  \n",
       "508       Mediterranean, hot summer  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's select some cities where we have good amount of images and different climates\n",
    "cities_df = pd.read_csv('../../data/0-raw/Global-StreetScapes/info/cities688.csv')\n",
    "\n",
    "# Select the desired columns\n",
    "selected_columns = ['city', 'img_count', 'continent', 'koppen_geiger_zone', 'zone_description']\n",
    "\n",
    "# Create a list of cities to filter\n",
    "selected_cities = ['Amsterdam', 'Barcelona', 'Berlin', 'London', 'Athens', 'Lisbon']\n",
    "\n",
    "# Create a table of selected cities with the desired columns, ordered by img_count in descending order\n",
    "cities_table = cities_df[cities_df['city'].isin(selected_cities)][selected_columns].sort_values('img_count', ascending=False)\n",
    "\n",
    "# Display the selected cities\n",
    "cities_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate.csv</td>\n",
       "      <td>Contains the Koppen climate zone associated with each image's location.</td>\n",
       "      <td>The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the Koppen climate zone classification API from https://github.com/sco-tt/Climate-Zone-API.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contextual.csv</td>\n",
       "      <td>Contains the eight contextual attributes inferred for each image.</td>\n",
       "      <td>Please refer to Table 3 in the paper for information on accuracy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ephem.csv</td>\n",
       "      <td>Contains the temporal information of each image calculated using the python package 'PyEphem' with regards to the time of day.</td>\n",
       "      <td>The accuracy of the calculation is as accurate as the timestamp of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of PyEphem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gadm.csv</td>\n",
       "      <td>Contains the administrative area associated with each image, at all available levels.</td>\n",
       "      <td>The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the GADM database.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ghsl.csv</td>\n",
       "      <td>Contains the degree of urbanisation associated with the location of the image, calculated using the Global Human Settlement Layer (GHSL).</td>\n",
       "      <td>The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the GHSL dataset.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h3.csv</td>\n",
       "      <td>Contains the ID of the h3-indexed hexagon associated with each image, at all available resolution levels from level 0 to 15.</td>\n",
       "      <td>The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>instances.csv</td>\n",
       "      <td>Contains the count of instances (65 categories) detected in each image.</td>\n",
       "      <td>Based on panoptic segmentation results obtained with Mask2former model. Accuracy is dependent on model performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metadata_common_attributes.csv</td>\n",
       "      <td>Contains the common basic metadata attributes that are provided by both Mapillary and KartaView, and those we computed for both sources.</td>\n",
       "      <td>Accuracy is subject to that of the original metadata provided by Mapillary / KartaView, which also largely depends on the accuracy of data provided by the capturing devices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>metadata_kv.csv</td>\n",
       "      <td>Contains the metadata of each SVI originally provided by KartaView.</td>\n",
       "      <td>The explanation of the fields is largely based on our interpretation of the documentation of KartaView API, which can be incomplete or absent for many attributes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>metadata_mly1.csv</td>\n",
       "      <td>Contains the metadata of each SVI originally provided by Mapillary.</td>\n",
       "      <td>Split into five parts (metadata_mly1, metadata_mly2, metadata_mly3, metadata_mly4, metadata_mly5) to reduce file size.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>metadata_mly2.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>metadata_mly3.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>metadata_mly4.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>metadata_mly5.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>osm.csv</td>\n",
       "      <td>Contains the information of the OSM street found nearest to each image within its 10 m radius.</td>\n",
       "      <td>The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the OSM dataset. OSM street networks were obtained through the OSMnx package.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>perception.csv</td>\n",
       "      <td>Contains the scores, in scale of 0-10, predicted for each of six perceptual dimensions (Safe, Lively, Beautiful, Wealthy, Boring, Depressing).</td>\n",
       "      <td>Contains the predicted scores (in scale of 0-10, high score indicates strong feeling) of human subjective perceptions, using model trained on the Place Pulse 2.0. Accuracy depends on model performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>places365.csv</td>\n",
       "      <td>Contains the place/scene classification for each image.</td>\n",
       "      <td>Obtained from model pre-trained on the Places dataset which has over 400 categories for a variety of places and scenes. Accuracy depends on model performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>season.csv</td>\n",
       "      <td>Contains the season determined for each image based on climate zone and month.</td>\n",
       "      <td>Accuracy depends on the temporal and spatial accuracy of the image given by source, and the accuracy of the Köppen climate clasiffication zones used.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>segmentation.csv</td>\n",
       "      <td>Contains the count of segmented pixels of each semantic classes (65 categories in total) identified in the image.</td>\n",
       "      <td>Based on panoptic segmentation results obtained with Mask2former model. Accuracy is dependent on model performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>simplemaps.csv</td>\n",
       "      <td>Contains the information of the city associated with the image, obtained from the World Cities database by Simplemaps.</td>\n",
       "      <td>The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the World Cities database.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>speed.csv</td>\n",
       "      <td>Contains various statistical values related to speed for each image.</td>\n",
       "      <td>Calculation accuracy depends on the accuracy of location and capture time from the source metadata, which also depends on the accuracy of such data from the capturing device.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Filename  \\\n",
       "0                      climate.csv   \n",
       "1                   contextual.csv   \n",
       "2                        ephem.csv   \n",
       "3                         gadm.csv   \n",
       "4                         ghsl.csv   \n",
       "5                           h3.csv   \n",
       "6                    instances.csv   \n",
       "7   metadata_common_attributes.csv   \n",
       "8                  metadata_kv.csv   \n",
       "9                metadata_mly1.csv   \n",
       "10               metadata_mly2.csv   \n",
       "11               metadata_mly3.csv   \n",
       "12               metadata_mly4.csv   \n",
       "13               metadata_mly5.csv   \n",
       "14                         osm.csv   \n",
       "15                  perception.csv   \n",
       "16                   places365.csv   \n",
       "17                      season.csv   \n",
       "18                segmentation.csv   \n",
       "19                  simplemaps.csv   \n",
       "20                       speed.csv   \n",
       "\n",
       "                                                                                                                                          Overview  \\\n",
       "0                                                                          Contains the Koppen climate zone associated with each image's location.   \n",
       "1                                                                                Contains the eight contextual attributes inferred for each image.   \n",
       "2                   Contains the temporal information of each image calculated using the python package 'PyEphem' with regards to the time of day.   \n",
       "3                                                            Contains the administrative area associated with each image, at all available levels.   \n",
       "4        Contains the degree of urbanisation associated with the location of the image, calculated using the Global Human Settlement Layer (GHSL).   \n",
       "5                     Contains the ID of the h3-indexed hexagon associated with each image, at all available resolution levels from level 0 to 15.   \n",
       "6                                                                          Contains the count of instances (65 categories) detected in each image.   \n",
       "7         Contains the common basic metadata attributes that are provided by both Mapillary and KartaView, and those we computed for both sources.   \n",
       "8                                                                              Contains the metadata of each SVI originally provided by KartaView.   \n",
       "9                                                                              Contains the metadata of each SVI originally provided by Mapillary.   \n",
       "10                                                                                                                                             NaN   \n",
       "11                                                                                                                                             NaN   \n",
       "12                                                                                                                                             NaN   \n",
       "13                                                                                                                                             NaN   \n",
       "14                                                  Contains the information of the OSM street found nearest to each image within its 10 m radius.   \n",
       "15  Contains the scores, in scale of 0-10, predicted for each of six perceptual dimensions (Safe, Lively, Beautiful, Wealthy, Boring, Depressing).   \n",
       "16                                                                                         Contains the place/scene classification for each image.   \n",
       "17                                                                  Contains the season determined for each image based on climate zone and month.   \n",
       "18                               Contains the count of segmented pixels of each semantic classes (65 categories in total) identified in the image.   \n",
       "19                          Contains the information of the city associated with the image, obtained from the World Cities database by Simplemaps.   \n",
       "20                                                                            Contains various statistical values related to speed for each image.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                              Notes  \n",
       "0   The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the Koppen climate zone classification API from https://github.com/sco-tt/Climate-Zone-API.  \n",
       "1                                                                                                                                                                                                                                 Please refer to Table 3 in the paper for information on accuracy.  \n",
       "2                                                                     The accuracy of the calculation is as accurate as the timestamp of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of PyEphem.  \n",
       "3                                                                            The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the GADM database.  \n",
       "4                                                                             The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the GHSL dataset.  \n",
       "5                                                                                                                                                      The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices.  \n",
       "6                                                                                                                                                                               Based on panoptic segmentation results obtained with Mask2former model. Accuracy is dependent on model performance.  \n",
       "7                                                                                                                     Accuracy is subject to that of the original metadata provided by Mapillary / KartaView, which also largely depends on the accuracy of data provided by the capturing devices.  \n",
       "8                                                                                                                                The explanation of the fields is largely based on our interpretation of the documentation of KartaView API, which can be incomplete or absent for many attributes.  \n",
       "9                                                                                                                                                                            Split into five parts (metadata_mly1, metadata_mly2, metadata_mly3, metadata_mly4, metadata_mly5) to reduce file size.  \n",
       "10                                                                                                                                                                                                                                                                                              NaN  \n",
       "11                                                                                                                                                                                                                                                                                              NaN  \n",
       "12                                                                                                                                                                                                                                                                                              NaN  \n",
       "13                                                                                                                                                                                                                                                                                              NaN  \n",
       "14                The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the OSM dataset. OSM street networks were obtained through the OSMnx package.  \n",
       "15                                                                                        Contains the predicted scores (in scale of 0-10, high score indicates strong feeling) of human subjective perceptions, using model trained on the Place Pulse 2.0. Accuracy depends on model performance.  \n",
       "16                                                                                                                                   Obtained from model pre-trained on the Places dataset which has over 400 categories for a variety of places and scenes. Accuracy depends on model performance.  \n",
       "17                                                                                                                                            Accuracy depends on the temporal and spatial accuracy of the image given by source, and the accuracy of the Köppen climate clasiffication zones used.  \n",
       "18                                                                                                                                                                              Based on panoptic segmentation results obtained with Mask2former model. Accuracy is dependent on model performance.  \n",
       "19                                                                   The calculation is as accurate as the location of the image given by the source, which also relies on the accuracy of the capturing devices. The accuracy could also be affected by the accuracy of the World Cities database.  \n",
       "20                                                                                                                   Calculation accuracy depends on the accuracy of location and capture time from the source metadata, which also depends on the accuracy of such data from the capturing device.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Read the info.csv file\n",
    "info_df = pd.read_csv('../../data/0-raw/Global-StreetScapes/info/info.csv')\n",
    "\n",
    "# Display only 'Filename' and 'Overview' columns where 'Filename' is not null\n",
    "display_columns = ['Filename', 'Overview', 'Notes']\n",
    "display_df = info_df[display_columns].dropna(subset=['Filename'])\n",
    "\n",
    "# Reset the index and drop it to remove the index column\n",
    "display_df = display_df.reset_index(drop=True)\n",
    "\n",
    "# Set display options to show full content of 'Overview' column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Display the data\n",
    "display(display_df)\n",
    "\n",
    "# Reset display options to default\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c295f0ec7ef4c998412e1232d93d952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Filename:', layout=Layout(width='30%'), options=('Select a filename', 'cl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0388cfd5d8d48eaaf75eaaf372924fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Load the CSV and propagate Filename values\n",
    "info_df = pd.read_csv('../../data/0-raw/Global-StreetScapes/info/info.csv').ffill()\n",
    "\n",
    "# Set display options to show full content of all columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Create a dropdown for Filename selection with an \"All\" option\n",
    "filename_dropdown = widgets.Dropdown(\n",
    "    options=['Select a filename'] + info_df['Filename'].unique().tolist(),\n",
    "    value='Select a filename',  # Default to the indicator value\n",
    "    description='Filename:',\n",
    "    layout=widgets.Layout(width='30%')\n",
    ")\n",
    "\n",
    "# Create a search text box for Field filtering without a dropdown\n",
    "field_search = widgets.Text(\n",
    "    placeholder='Type to search fields...',\n",
    "    description='Field:',\n",
    "    layout=widgets.Layout(width='30%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to filter and display data based on selected filename and field\n",
    "def filter_data(change=None):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # If the placeholder option is selected, show a message\n",
    "        if filename_dropdown.value == 'Select a filename':\n",
    "            display(HTML(\"<p><b>Please select a filename to view the data.</b></p>\"))\n",
    "            return\n",
    "        \n",
    "        # Filter the data\n",
    "        filtered_df = info_df.copy()\n",
    "        \n",
    "        # Filter by Filename if not \"All\"\n",
    "        if filename_dropdown.value != 'All':\n",
    "            filtered_df = filtered_df[filtered_df['Filename'] == filename_dropdown.value]\n",
    "\n",
    "        # Filter by field if there is text in the field_search box\n",
    "        if field_search.value.strip():\n",
    "            filtered_df = filtered_df[filtered_df['Field'].str.contains(field_search.value, case=False, na=False)]\n",
    "\n",
    "        # Display the filtered data with adjusted column widths\n",
    "        if not filtered_df.empty:\n",
    "            html_table = filtered_df[['Filename', 'Field', 'Format', 'Explanation']].to_html(index=False)\n",
    "            styled_table = f\"\"\"\n",
    "            <style>\n",
    "            table {{width: 100%;}}\n",
    "            th, td {{\n",
    "                word-wrap: break-word;\n",
    "                max-width: 700px;\n",
    "                overflow: hidden;\n",
    "                text-overflow: ellipsis;\n",
    "            }}\n",
    "            th:nth-child(1), td:nth-child(1) {{max-width: 120px;}}  /* Filename column */\n",
    "            th:nth-child(4), td:nth-child(4) {{max-width: 600px;}}  /* Explanation column */\n",
    "            </style>\n",
    "            {html_table}\n",
    "            \"\"\"\n",
    "            display(HTML(styled_table))\n",
    "        else:\n",
    "            display(HTML(\"<p>No results found.</p>\"))\n",
    "\n",
    "# Attach functions to widget events\n",
    "filename_dropdown.observe(filter_data, names='value')\n",
    "field_search.observe(filter_data, names='value')\n",
    "\n",
    "# Display widgets\n",
    "widget_box = widgets.HBox([filename_dropdown, field_search])\n",
    "display(widget_box, output)\n",
    "\n",
    "# Initial message to guide the user\n",
    "filter_data()\n",
    "\n",
    "# Reset display options to default\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban-heat-dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
